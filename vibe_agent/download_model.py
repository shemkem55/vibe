"""
Model Downloader
Downloads the requested model for local use.
"""

import os
import shutil
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

def download_model(model_id="microsoft/Phi-3-mini-4k-instruct", save_dir="./models/phi-3-mini"):
    print(f"üöÄ Starting download for {model_id}...")
    print(f"üìÇ Destination: {save_dir}")
    
    if os.path.exists(save_dir):
        print("‚ö†Ô∏è Model directory already exists. Checking contents...")
        if os.path.exists(os.path.join(save_dir, "config.json")):
            print("‚úÖ Model appears to be present. Use --force to redownload.")
            return

    try:
        print("‚è≥ Downloading Tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)
        tokenizer.save_pretrained(save_dir)
        
        print("‚è≥ Downloading Model (this may take a while)...")
        model = AutoModelForCausalLM.from_pretrained(
            model_id,
            torch_dtype=torch.float16,
            trust_remote_code=True,
            device_map="auto"
        )
        model.save_pretrained(save_dir)
        
        print("üéâ Download complete!")
        print(f"Path: {os.path.abspath(save_dir)}")
        
    except Exception as e:
        print(f"‚ùå Error downloading model: {e}")

if __name__ == "__main__":
    download_model()
